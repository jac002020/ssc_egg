{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import slp_data\n",
    "import config\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split recordings to train test and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_recs = []\n",
    "for f in os.listdir(config.data_dir):\n",
    "    if f.endswith('.lbl'):\n",
    "        all_recs.append(f.split('.')[0])\n",
    "all_recs = np.asarray(all_recs, dtype=np.str)\n",
    "num_recs = len(all_recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "num_steps = 1000\n",
    "batch_size = 128\n",
    "display_step = 10\n",
    "strides = 1\n",
    "#pooling kernel size and sride\n",
    "k = 2\n",
    "\n",
    "# Network Parameters\n",
    "num_input = 30*250\n",
    "num_classes = len(slp_data.DataSet.all_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv1D, Flatten, MaxPooling1D\n",
    "drop_out_rate = 0.4\n",
    "#Initializing Neural Network\n",
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Conv1D(filters=32, \n",
    "                      kernel_size=5,\n",
    "                      strides=1, \n",
    "                      padding='valid', \n",
    "                      dilation_rate=1, \n",
    "                      activation='relu',                      \n",
    "                      input_shape=(num_input, 1)\n",
    "\n",
    "))\n",
    "\n",
    "classifier.add(MaxPooling1D(pool_size=2, \n",
    "                            strides=None, \n",
    "                            padding='valid'\n",
    "))\n",
    "classifier.add(Dropout(drop_out_rate))\n",
    "\n",
    "classifier.add(Conv1D(filters=64, \n",
    "                      kernel_size=5,\n",
    "                      strides=1, \n",
    "                      padding='valid', \n",
    "                      dilation_rate=1, \n",
    "                      activation='relu'\n",
    "))\n",
    "classifier.add(MaxPooling1D(pool_size=2, \n",
    "                            strides=None, \n",
    "                            padding='valid', \n",
    "))\n",
    "classifier.add(Dropout(drop_out_rate))\n",
    "\n",
    "classifier.add(Conv1D(filters=128, \n",
    "                      kernel_size=5,\n",
    "                      strides=1, \n",
    "                      padding='valid', \n",
    "                      dilation_rate=1, \n",
    "                      activation='relu'\n",
    "))\n",
    "classifier.add(MaxPooling1D(pool_size=2, \n",
    "                            strides=None, \n",
    "                            padding='valid', \n",
    "))\n",
    "classifier.add(Dropout(drop_out_rate))\n",
    "\n",
    "classifier.add(Conv1D(filters=256, \n",
    "                      kernel_size=5,\n",
    "                      strides=1, \n",
    "                      padding='valid', \n",
    "                      dilation_rate=1, \n",
    "                      activation='relu'\n",
    "))\n",
    "classifier.add(MaxPooling1D(pool_size=2, \n",
    "                            strides=None, \n",
    "                            padding='valid', \n",
    "))\n",
    "classifier.add(Dropout(drop_out_rate))\n",
    "\n",
    "classifier.add(Flatten())\n",
    "classifier.add(Dropout(drop_out_rate))\n",
    "classifier.add(Dense(units = 512, kernel_initializer = 'random_uniform', activation = 'relu'))\n",
    "classifier.add(Dropout(drop_out_rate))\n",
    "classifier.add(Dense(units = 512, kernel_initializer = 'random_uniform', activation = 'relu'))\n",
    "classifier.add(Dropout(drop_out_rate))\n",
    "classifier.add(Dense(units = 512, kernel_initializer = 'random_uniform', activation = 'relu'))\n",
    "classifier.add(Dropout(drop_out_rate))\n",
    "classifier.add(Dense(units = 256, kernel_initializer = 'random_uniform', activation = 'relu'))\n",
    "classifier.add(Dropout(drop_out_rate))\n",
    "classifier.add(Dense(units = 128, kernel_initializer = 'random_uniform', activation = 'relu'))\n",
    "classifier.add(Dropout(drop_out_rate))\n",
    "classifier.add(Dense(units = 128, kernel_initializer = 'random_uniform', activation = 'relu'))\n",
    "classifier.add(Dropout(drop_out_rate))\n",
    "classifier.add(Dense(units = 128, kernel_initializer = 'random_uniform', activation = 'relu'))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(units = num_classes, kernel_initializer = 'random_uniform', activation = 'softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "early_callback = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, \n",
    "                              patience=4, verbose=1, \n",
    "                              mode='auto')\n",
    "lr_callback = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.95, \n",
    "                                                patience=1, verbose=1, \n",
    "                                                mode='auto', cooldown=0, min_lr=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, cohen_kappa_score\n",
    "from sklearn.model_selection import KFold\n",
    "from classification_report import ClassificationReport\n",
    "\n",
    "fold_results = []\n",
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "for train_records_index, test_records_index in kf.split(all_recs):\n",
    "    \n",
    "    train_recs = all_recs[train_records_index]\n",
    "    test_recs = all_recs[test_records_index]\n",
    "    \n",
    "    val_recs = train_recs[-1:]\n",
    "    train_recs = train_recs[:-1]\n",
    "    print(\"train recordings: {}\".format(train_recs))\n",
    "    print(\"test recordings: {}\".format(test_recs))\n",
    "    \n",
    "    data = slp_data.SlpDataSet(config.data_dir, \n",
    "                               train_recs,\n",
    "                               val_recs, \n",
    "                               test_recs, one_hot=True)\n",
    "    \n",
    "    \n",
    "    train_x, train_y = data.train.all_examples(shuffle=True)\n",
    "    train_x = train_x.reshape((-1, 250*30, 1))\n",
    "    \n",
    "    val_x, val_y = data.validation.all_examples(shuffle=False)\n",
    "    val_x = val_x.reshape((-1, 250*30, 1))\n",
    "    \n",
    "    # Compiling Neural Network\n",
    "    classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    classifier.fit(train_x, train_y, \n",
    "                   batch_size = 128, nb_epoch = 40, \n",
    "                   validation_data=(val_x, val_y), shuffle=True, \n",
    "                   callbacks=[early_callback, lr_callback])\n",
    "    \n",
    "    test_x, test_y = data.test.all_examples(shuffle=False)\n",
    "    test_x = test_x.reshape((-1, 250*30, 1))\n",
    "    test_prediction = np.argmax(classifier.predict(test_x), axis=1)\n",
    "    label_y = np.argmax(test_y, axis=1)\n",
    "    r = ClassificationReport(test_prediction, label_y)\n",
    "    \n",
    "    fold_results.append(r)\n",
    "    print(r)\n",
    "    break \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
